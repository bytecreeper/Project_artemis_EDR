"""
Pentest Report Generator - Professional Security Assessment Reports

Generates comprehensive penetration testing reports with:
- Executive summary
- Vulnerability findings with CVSS scores
- Proof-of-concept evidence
- Remediation recommendations
- Technical appendices

Output formats: Markdown, HTML, PDF (via WeasyPrint)
"""

import json
import logging
import time
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

from .agents import BaseAgent, AgentResult

logger = logging.getLogger("artemis.pentest.report")


REPORT_SYSTEM_PROMPT = """You are a professional penetration testing report writer.

Generate comprehensive, client-ready penetration testing reports with:
1. Executive Summary - Business-focused overview
2. Methodology - Testing approach and scope
3. Findings Summary - Risk matrix and statistics
4. Detailed Findings - Each vulnerability with evidence
5. Remediation Roadmap - Prioritized fix recommendations
6. Technical Appendices - Raw data and proof-of-concept details

For each finding, include:
- Severity (Critical/High/Medium/Low/Info)
- CVSS v3.1 score estimate
- Description
- Impact
- Proof of Concept
- Remediation

Write in professional, clear language suitable for both technical and executive audiences.
"""


@dataclass
class ReportResult:
    """Result from report generation."""
    success: bool
    report_path: Optional[str] = None
    error: Optional[str] = None


class ReportGenerator(BaseAgent):
    """
    Generates professional penetration testing reports.
    
    Produces:
    - pentest_report.md - Full markdown report
    - pentest_report.html - Styled HTML report
    - executive_summary.md - One-page executive summary
    """
    
    agent_name = "report"
    agent_role = "Report Generator"
    
    def __init__(
        self,
        vulnerabilities: list[dict],
        recon_data: Optional[dict],
        agent_metrics: dict,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.vulnerabilities = vulnerabilities
        self.recon_data = recon_data or {}
        self.agent_metrics = agent_metrics
    
    def get_system_prompt(self) -> str:
        return REPORT_SYSTEM_PROMPT
    
    async def run(self) -> AgentResult:
        """Generate the penetration testing report."""
        self.start_time = time.time()
        
        logger.info("Generating penetration testing report...")
        
        try:
            # Generate report sections
            executive_summary = await self._generate_executive_summary()
            findings_detail = self._generate_findings_detail()
            remediation_roadmap = await self._generate_remediation_roadmap()
            appendices = self._generate_appendices()
            
            # Compile full report
            report = self._compile_report(
                executive_summary,
                findings_detail,
                remediation_roadmap,
                appendices,
            )
            
            # Write reports
            md_path = self.deliverables_dir / "pentest_report.md"
            md_path.write_text(report)
            
            # Generate HTML version
            html_path = self.deliverables_dir / "pentest_report.html"
            self._write_html_report(html_path, report)
            
            # Generate executive summary
            exec_path = self.deliverables_dir / "executive_summary.md"
            exec_path.write_text(executive_summary)
            
            duration_ms = int((time.time() - self.start_time) * 1000)
            
            return AgentResult(
                success=True,
                turns=self.turns,
                tokens_used=self.tokens_used,
                duration_ms=duration_ms,
                deliverable_path=str(md_path),
            )
            
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return AgentResult(
                success=False,
                turns=self.turns,
                error=str(e),
            )
    
    async def _generate_executive_summary(self) -> str:
        """Generate executive summary using LLM."""
        severity_counts = self._count_by_severity()
        
        prompt = f"""Generate a professional executive summary for a penetration testing report.

## Target
{self.config.target_url}

## Test Duration
{self._get_test_duration()}

## Findings Overview
- Critical: {severity_counts.get('critical', 0)}
- High: {severity_counts.get('high', 0)}
- Medium: {severity_counts.get('medium', 0)}
- Low: {severity_counts.get('low', 0)}
- Informational: {severity_counts.get('info', 0)}

## Top Vulnerabilities
{self._format_top_vulns()}

Write a 1-2 page executive summary covering:
1. Assessment overview
2. Key findings
3. Overall risk rating
4. Critical recommendations

Use professional language suitable for C-level executives.
"""
        
        response = await self.query_llm(prompt)
        return response
    
    async def _generate_remediation_roadmap(self) -> str:
        """Generate prioritized remediation roadmap."""
        prompt = f"""Generate a prioritized remediation roadmap for these vulnerabilities:

{json.dumps(self.vulnerabilities, indent=2)}

Create a roadmap with:
1. Immediate actions (0-7 days) - Critical/High severity
2. Short-term actions (1-4 weeks) - Medium severity
3. Long-term improvements (1-3 months) - Low severity + hardening

For each item, include:
- Priority level
- Affected components
- Remediation steps
- Estimated effort
- Dependencies

Format as a clear, actionable remediation plan.
"""
        
        response = await self.query_llm(prompt)
        return response
    
    def _generate_findings_detail(self) -> str:
        """Generate detailed findings section."""
        if not self.vulnerabilities:
            return """## Detailed Findings

No exploitable vulnerabilities were confirmed during this assessment.

The security controls in place effectively prevented exploitation of potential attack vectors.
"""
        
        sections = ["## Detailed Findings\n"]
        
        # Sort by severity
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}
        sorted_vulns = sorted(
            self.vulnerabilities,
            key=lambda v: severity_order.get(v.get("severity", "medium").lower(), 2)
        )
        
        for i, vuln in enumerate(sorted_vulns, 1):
            severity = vuln.get("severity", "Medium").upper()
            cvss = self._estimate_cvss(vuln)
            
            section = f"""
### {i}. {vuln.get('title', 'Unknown Vulnerability')}

| Attribute | Value |
|-----------|-------|
| **Severity** | {severity} |
| **CVSS Score** | {cvss} |
| **Type** | {vuln.get('type', 'Unknown')} |
| **Endpoint** | `{vuln.get('endpoint', 'N/A')}` |
| **Parameter** | `{vuln.get('parameter', 'N/A')}` |
| **File** | `{vuln.get('file_path', 'N/A')}:{vuln.get('line_number', '')}` |

#### Description
{vuln.get('description', 'No description provided.')}

#### Impact
{vuln.get('impact', 'Could allow unauthorized access or data manipulation.')}

#### Proof of Concept
```
{vuln.get('payload', 'N/A')}
```

**Exploitation Evidence:**
```
{vuln.get('exploit_proof', 'Vulnerability confirmed through automated testing.')}
```

#### Remediation
{vuln.get('remediation', 'Implement proper input validation and output encoding.')}

---
"""
            sections.append(section)
        
        return "\n".join(sections)
    
    def _generate_appendices(self) -> str:
        """Generate technical appendices."""
        appendix = """## Appendices

### A. Methodology

This assessment followed industry-standard penetration testing methodology:

1. **Reconnaissance** - Attack surface mapping and technology identification
2. **Vulnerability Analysis** - Automated and manual security testing
3. **Exploitation** - Proof-of-concept development for confirmed vulnerabilities
4. **Reporting** - Documentation of findings with remediation guidance

### B. Tools Used

- Artemis Security Platform (AI-powered analysis)
- Nmap (network scanning)
- Custom exploitation scripts
- Manual code review

### C. Testing Statistics

"""
        # Add agent metrics
        for agent_name, metrics in self.agent_metrics.items():
            appendix += f"- **{agent_name}**: {metrics.duration_ms}ms"
            if hasattr(metrics, 'findings_count') and metrics.findings_count:
                appendix += f" ({metrics.findings_count} findings)"
            appendix += "\n"
        
        # Add scope
        appendix += f"""
### D. Scope

**Target:** {self.config.target_url}
**Repository:** {self.config.repo_path or 'Blackbox assessment'}
**Assessment Type:** {'Whitebox' if self.config.repo_path else 'Blackbox'}
"""
        
        return appendix
    
    def _compile_report(
        self,
        executive_summary: str,
        findings_detail: str,
        remediation_roadmap: str,
        appendices: str,
    ) -> str:
        """Compile the full report."""
        header = f"""# Penetration Testing Report

**Target:** {self.config.target_url}  
**Date:** {datetime.now(timezone.utc).strftime('%Y-%m-%d')}  
**Prepared By:** Artemis Security Platform  

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Methodology](#methodology)
3. [Findings Summary](#findings-summary)
4. [Detailed Findings](#detailed-findings)
5. [Remediation Roadmap](#remediation-roadmap)
6. [Appendices](#appendices)

---

## Executive Summary

{executive_summary}

---

## Findings Summary

{self._generate_findings_summary()}

---

{findings_detail}

---

## Remediation Roadmap

{remediation_roadmap}

---

{appendices}

---

*Report generated by Artemis Security Platform*
"""
        return header
    
    def _generate_findings_summary(self) -> str:
        """Generate findings summary with risk matrix."""
        severity_counts = self._count_by_severity()
        type_counts = self._count_by_type()
        
        summary = f"""### Risk Matrix

| Severity | Count | Percentage |
|----------|-------|------------|
| Critical | {severity_counts.get('critical', 0)} | {self._percent(severity_counts.get('critical', 0))}% |
| High | {severity_counts.get('high', 0)} | {self._percent(severity_counts.get('high', 0))}% |
| Medium | {severity_counts.get('medium', 0)} | {self._percent(severity_counts.get('medium', 0))}% |
| Low | {severity_counts.get('low', 0)} | {self._percent(severity_counts.get('low', 0))}% |
| Info | {severity_counts.get('info', 0)} | {self._percent(severity_counts.get('info', 0))}% |
| **Total** | **{len(self.vulnerabilities)}** | **100%** |

### Findings by Type

| Vulnerability Type | Count |
|--------------------|-------|
"""
        for vtype, count in type_counts.items():
            summary += f"| {vtype.upper()} | {count} |\n"
        
        return summary
    
    def _count_by_severity(self) -> dict:
        """Count vulnerabilities by severity."""
        counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        for v in self.vulnerabilities:
            sev = v.get("severity", "medium").lower()
            if sev in counts:
                counts[sev] += 1
        return counts
    
    def _count_by_type(self) -> dict:
        """Count vulnerabilities by type."""
        counts = {}
        for v in self.vulnerabilities:
            vtype = v.get("type", "unknown")
            counts[vtype] = counts.get(vtype, 0) + 1
        return counts
    
    def _percent(self, count: int) -> str:
        """Calculate percentage."""
        total = len(self.vulnerabilities)
        if total == 0:
            return "0"
        return f"{(count / total * 100):.1f}"
    
    def _format_top_vulns(self) -> str:
        """Format top vulnerabilities for executive summary."""
        if not self.vulnerabilities:
            return "No critical vulnerabilities found."
        
        # Get top 5 by severity
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}
        sorted_vulns = sorted(
            self.vulnerabilities,
            key=lambda v: severity_order.get(v.get("severity", "medium").lower(), 2)
        )[:5]
        
        lines = []
        for v in sorted_vulns:
            lines.append(f"- [{v.get('severity', 'Medium').upper()}] {v.get('title', 'Unknown')}")
        
        return "\n".join(lines)
    
    def _get_test_duration(self) -> str:
        """Calculate total test duration."""
        total_ms = sum(m.duration_ms for m in self.agent_metrics.values())
        seconds = total_ms / 1000
        if seconds < 60:
            return f"{seconds:.1f} seconds"
        elif seconds < 3600:
            return f"{seconds / 60:.1f} minutes"
        else:
            return f"{seconds / 3600:.1f} hours"
    
    def _estimate_cvss(self, vuln: dict) -> str:
        """Estimate CVSS score based on vulnerability attributes."""
        severity = vuln.get("severity", "medium").lower()
        vuln_type = vuln.get("type", "unknown").lower()
        
        # Base CVSS ranges by severity
        cvss_ranges = {
            "critical": "9.0-10.0",
            "high": "7.0-8.9",
            "medium": "4.0-6.9",
            "low": "0.1-3.9",
            "info": "0.0",
        }
        
        # More specific estimates by type
        type_cvss = {
            "injection": {"critical": "9.8", "high": "8.6"},
            "xss": {"high": "6.1", "medium": "5.4"},
            "auth": {"critical": "9.8", "high": "8.1"},
            "authz": {"critical": "9.1", "high": "7.5"},
            "ssrf": {"critical": "9.1", "high": "7.2"},
        }
        
        if vuln_type in type_cvss and severity in type_cvss[vuln_type]:
            return type_cvss[vuln_type][severity]
        
        return cvss_ranges.get(severity, "5.0")
    
    def _write_html_report(self, path: Path, markdown_content: str):
        """Convert markdown to styled HTML report."""
        try:
            import markdown
            html_body = markdown.markdown(
                markdown_content,
                extensions=['tables', 'fenced_code', 'toc']
            )
        except ImportError:
            # Fallback: wrap in pre tags
            html_body = f"<pre>{markdown_content}</pre>"
        
        html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Penetration Testing Report - {self.config.target_url}</title>
    <style>
        :root {{
            --bg-primary: #0d1117;
            --bg-secondary: #161b22;
            --text-primary: #c9d1d9;
            --text-secondary: #8b949e;
            --accent: #58a6ff;
            --critical: #f85149;
            --high: #ff7b72;
            --medium: #d29922;
            --low: #3fb950;
            --info: #8b949e;
        }}
        
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.6;
            padding: 2rem;
            max-width: 1200px;
            margin: 0 auto;
        }}
        
        h1, h2, h3 {{
            color: var(--accent);
            margin: 1.5rem 0 1rem 0;
        }}
        
        h1 {{
            font-size: 2.5rem;
            border-bottom: 2px solid var(--accent);
            padding-bottom: 0.5rem;
        }}
        
        h2 {{
            font-size: 1.8rem;
        }}
        
        h3 {{
            font-size: 1.4rem;
        }}
        
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            background: var(--bg-secondary);
        }}
        
        th, td {{
            padding: 0.75rem;
            text-align: left;
            border: 1px solid #30363d;
        }}
        
        th {{
            background: var(--bg-primary);
            color: var(--accent);
        }}
        
        code {{
            background: var(--bg-secondary);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Fira Code', 'Consolas', monospace;
        }}
        
        pre {{
            background: var(--bg-secondary);
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
            margin: 1rem 0;
        }}
        
        pre code {{
            padding: 0;
            background: none;
        }}
        
        hr {{
            border: none;
            border-top: 1px solid #30363d;
            margin: 2rem 0;
        }}
        
        a {{
            color: var(--accent);
        }}
        
        ul, ol {{
            margin: 1rem 0;
            padding-left: 2rem;
        }}
        
        li {{
            margin: 0.5rem 0;
        }}
        
        .severity-critical {{ color: var(--critical); font-weight: bold; }}
        .severity-high {{ color: var(--high); font-weight: bold; }}
        .severity-medium {{ color: var(--medium); font-weight: bold; }}
        .severity-low {{ color: var(--low); }}
        .severity-info {{ color: var(--info); }}
        
        @media print {{
            body {{
                background: white;
                color: black;
            }}
            
            h1, h2, h3 {{
                color: #0366d6;
            }}
            
            table {{
                background: white;
            }}
            
            pre, code {{
                background: #f6f8fa;
            }}
        }}
    </style>
</head>
<body>
{html_body}
</body>
</html>
"""
        path.write_text(html)
